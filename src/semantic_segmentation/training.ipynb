{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook take inspiration from the Nvidia's [SegNet](https://github.com/dusty-nv/pytorch-segmentation/tree/master)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "from semantic_segmentation.dataset import get_sets as get_semantic_sets\n",
    "from semantic_segmentation.dataset import InputType\n",
    "from ipywidgets import interact\n",
    "from utils.dataset import get_dataloader\n",
    "from params import PROJECT_PATH\n",
    "from sam_pipeline_utils import compute_semantic_segmentation, CostType\n",
    "from semantic_segmentation.sam_pipeline_utils import downsample_to_grid\n",
    "\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SegTrainingConfig:\n",
    "    dataset_dir: Path = (\n",
    "        PROJECT_PATH / \"datasets/Distillation dataset/dataset_distillation_all\"\n",
    "    )\n",
    "    weights: str = torchvision.models.segmentation.FCN_ResNet50_Weights.DEFAULT\n",
    "    batch_size: int = 64\n",
    "    num_epochs: int = 100\n",
    "    lr: float = 1e-3\n",
    "    lr_max_decay: float = 0.01\n",
    "    lr_decay_step: int = 50\n",
    "\n",
    "\n",
    "config = SegTrainingConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX: debug\n",
    "config = SegTrainingConfig(\n",
    "    dataset_dir=PROJECT_PATH\n",
    "    / \"datasets/Distillation dataset/fake_dataset_distillation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = get_semantic_sets(\n",
    "    config.dataset_dir,\n",
    "    image_augmentation_transform=None,\n",
    "    geometric_augmentation_transform=None,\n",
    ")\n",
    "train_loader, val_loader, test_loader = get_dataloader(\n",
    "    train_set, val_set, test_set, batch_size=config.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deeplabv3_mobilenet_v3_large',\n",
       " 'deeplabv3_resnet101',\n",
       " 'deeplabv3_resnet50',\n",
       " 'fcn_resnet101',\n",
       " 'fcn_resnet50',\n",
       " 'lraspp_mobilenet_v3_large']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.models.list_models(torchvision.models.segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.segmentation.fcn_resnet50(\n",
    "    weights=config.weights,\n",
    "    progress=True,\n",
    ")\n",
    "\n",
    "# Adapt for our task of traversal semantic segmentation\n",
    "model.classifier[-1] = torch.nn.Conv2d(\n",
    "    512, 1, kernel_size=(1, 1), stride=(1, 1)\n",
    ")\n",
    "model.aux_classifier[-1] = torch.nn.Conv2d(\n",
    "    256, 1, kernel_size=(1, 1), stride=(1, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCN(\n",
       "  (backbone): IntermediateLayerGetter(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): FCNHead(\n",
       "    (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (aux_classifier): FCNHead(\n",
       "    (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "    optimizer, 1, config.lr_max_decay, config.lr_decay_step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(inputs, target):\n",
    "    losses = {}\n",
    "    for name, x in inputs.items():\n",
    "        losses[name] = torch.nn.functional.mse_loss(x, target.unsqueeze(1))\n",
    "\n",
    "    if len(losses) == 1:\n",
    "        return losses[\"out\"]\n",
    "\n",
    "    return losses[\"out\"] + 0.5 * losses[\"aux\"]\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    return avg_train_loss\n",
    "\n",
    "\n",
    "def evaluate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_loader:\n",
    "            x_val = x_val.to(device)\n",
    "            y_val = y_val.to(device)\n",
    "\n",
    "            y_pred_val = model(x_val)[\"out\"]\n",
    "            val_loss += torch.nn.functional.mse_loss(\n",
    "                y_pred_val, y_val.unsqueeze(1)\n",
    "            ).item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config, model):\n",
    "    progress_bar = tqdm(range(config.num_epochs), desc=\"Epoch\")\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "\n",
    "    for _ in progress_bar:\n",
    "        train_loss = train(model, train_loader, optimizer, device)\n",
    "        val_loss = evaluate(model, val_loader, device)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "        progress_bar.set_description(\n",
    "            f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Epoch\"\n",
    "        )\n",
    "\n",
    "        train_loss_list.append(train_loss)\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "    return train_loss_list, val_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list, val_loss_list = train_model(config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"logs/model_2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.load(\"logs/model_2.pth\")\n",
    "model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_list, label=\"train loss\")\n",
    "# plt.plot(val_loss_list, label=\"val loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa5c3ede2f84419b0557887aec7f67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='index', max=7), Output()), _dom_classes=('widget-interacâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "visualization_set = train_set\n",
    "\n",
    "\n",
    "@interact\n",
    "def visualize_prediction(index: int = (0, len(visualization_set) - 1)):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image, target = visualization_set[index]\n",
    "        image = image.unsqueeze(0).to(device)\n",
    "        output = model(image)[\"out\"]\n",
    "\n",
    "    _, axes = plt.subplots(1, 5, figsize=(30, 4))\n",
    "\n",
    "    test_index = visualization_set.indexes[index]\n",
    "    whole_image_path = config.dataset_dir / f\"images/{test_index:05d}.png\"\n",
    "    whole_image = plt.imread(whole_image_path)\n",
    "    axes[0].imshow(whole_image)\n",
    "    axes[0].imshow(whole_image)\n",
    "    axes[0].axhline(whole_image.shape[0] // 2, linestyle=\"dotted\", color=\"red\")\n",
    "    axes[0].axis(\"off\")\n",
    "    axes[0].set_title(\"Source Image\")\n",
    "\n",
    "    axes[1].imshow(\n",
    "        target.squeeze().cpu().numpy(), cmap=\"hot_r\", vmin=2, vmax=6\n",
    "    )\n",
    "    axes[1].set_title(\"Target\")\n",
    "    axes[1].axis(\"off\")\n",
    "    colorbar = axes[2].imshow(\n",
    "        output.squeeze().cpu().numpy(), cmap=\"hot_r\", vmin=2, vmax=6\n",
    "    )\n",
    "    axes[2].set_title(\"Predicted Result\")\n",
    "    axes[2].axis(\"off\")\n",
    "\n",
    "    plt.colorbar(colorbar, ax=axes, shrink=0.5, location=\"bottom\")\n",
    "\n",
    "    whole_target = np.load(\n",
    "        config.dataset_dir / f\"targets/{test_index:05d}.npy\"\n",
    "    )\n",
    "\n",
    "    output = output.squeeze().cpu().numpy()\n",
    "    top_half = np.full_like(output, 5)\n",
    "    whole_output = np.vstack((top_half, output))\n",
    "\n",
    "    whole_output = resize(\n",
    "        whole_output,\n",
    "        whole_target.shape,\n",
    "        mode=\"reflect\",\n",
    "        anti_aliasing=True,\n",
    "    )\n",
    "\n",
    "    costmap1 = downsample_to_grid(whole_target)\n",
    "    costmap2 = downsample_to_grid(whole_output)\n",
    "\n",
    "    axes[3].imshow(costmap1, cmap=\"hot_r\", vmin=2, vmax=6)\n",
    "    axes[3].set_title(\"Target Costmap\")\n",
    "    axes[3].axis(\"off\")\n",
    "    axes[4].imshow(costmap2, cmap=\"hot_r\", vmin=2, vmax=6)\n",
    "    axes[4].set_title(\"Predicted Costmap\")\n",
    "    axes[4].axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distilled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import timeit\n",
    "\n",
    "model.eval()\n",
    "benchmark_image, _ = test_set[0]\n",
    "benchmark_image = benchmark_image.unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "%%timeit\n",
    "\n",
    "with torch.no_grad():\n",
    "    model(benchmark_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full SAM pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(img_path: Path) -> np.array:\n",
    "    with Image.open(img_path) as pil_img:\n",
    "        pil_img = pil_img.resize((180, 320))\n",
    "        return np.array(pil_img)\n",
    "\n",
    "\n",
    "img = get_image(config.dataset_dir / \"images\" / \"00000.png\")\n",
    "depth = get_image(config.dataset_dir / \"images\" / \"00000d.png\")\n",
    "normal = get_image(config.dataset_dir / \"images\" / \"00000n.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "%%timeit\n",
    "\n",
    "with torch.no_grad():\n",
    "    compute_semantic_segmentation(\n",
    "        img,\n",
    "        depth,\n",
    "        normal,\n",
    "        should_fill_segmentation=True,\n",
    "        cost_type=CostType.CENTERED,\n",
    "        should_filter_intersection=True,\n",
    "        completeness_threshold=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# XXX: time written below are computed with the 2 above %%timeit\n",
    "sam_pipeline_time = 2900\n",
    "distilled_pipeline_time = 4\n",
    "\n",
    "values = [sam_pipeline_time, distilled_pipeline_time]\n",
    "labels = [\n",
    "    \"SAM pipeline\",\n",
    "    f\"Distilled pipeline (x{sam_pipeline_time // distilled_pipeline_time} faster)\",\n",
    "]\n",
    "\n",
    "plt.bar(labels, values, color=[\"firebrick\", \"limegreen\"])\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Time (in log)\")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Comparison of SAM_pipeline and distilled_pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-12-14 11:50:11 38898:38898 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-12-14 11:50:12 38898:38898 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-12-14 11:50:12 38898:38898 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "    profile_memory=True,\n",
    "    with_stack=True,\n",
    ") as prof:\n",
    "    train(model, train_loader, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "prof.export_chrome_trace(\"trace.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traversability-analysis-FVBHScUm-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
